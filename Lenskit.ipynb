{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.datasets import ML100K\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms.als import ImplicitMF\n",
    "from lenskit.algorithms.svd import BiasedSVD\n",
    "from lenskit.algorithms.funksvd import FunkSVD\n",
    "from lenskit.algorithms import Recommender, als, item_knn, user_knn\n",
    "from lenskit.algorithms.basic import Popular, Bias\n",
    "from lenskit import topn\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Scipy Matrices\n",
    "ratingAll = sp.load_npz('UserItemMatrix.npz')\n",
    "ratingTrain = sp.load_npz('TrainUserItemMatrix.npz')\n",
    "ratingValid = sp.load_npz('ValidationUserItemMatrix.npz')\n",
    "ratingTest = sp.load_npz('TestUserItemMatrix.npz')\n",
    "\n",
    "## Load the LookUp Dictionaries\n",
    "songToIndex = pickle.load(open('songIdToIndex.p','rb'))\n",
    "songIndexToId = pickle.load(open('songIndexToId.p','rb'))\n",
    "DFLookUp = pd.DataFrame.from_dict(songIndexToId, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Train, Validation and Test from the Scipy Matrices in DF format with columns user, item and rating\n",
    "listOfListsTrain = []\n",
    "for i in range(ratingTrain.shape[0]-900000):\n",
    "    for j in ratingTrain[i].nonzero()[1].tolist():\n",
    "        listOfListsTrain.append([i, j])\n",
    "train = pd.DataFrame(listOfListsTrain, columns=['user', 'item'])\n",
    "train['rating'] = 1\n",
    "\n",
    "listOfListsValidation = []\n",
    "for i in range(ratingValid.shape[0]-990000):\n",
    "    for j in ratingTest[i].nonzero()[1].tolist():\n",
    "        listOfListsValidation.append([i, j])\n",
    "validation = pd.DataFrame(listOfListsValidation, columns=['user', 'item'])\n",
    "validation['rating'] = 1\n",
    "\n",
    "listOfListsTest = []\n",
    "for i in range(ratingTest.shape[0]-990000):\n",
    "    for j in ratingTest[i].nonzero()[1].tolist():\n",
    "        listOfListsTest.append([i, j])\n",
    "test = pd.DataFrame(listOfListsTest, columns=['user', 'item'])\n",
    "test['rating'] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lenskit.algorithms.ranking.TopN at 0x777c06e00>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fit the model\n",
    "\n",
    "algo = Recommender.adapt(ImplicitMF(features=4)) # Required by Lenskit Library\n",
    "algo.fit(train) # Fit The model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1663</td>\n",
       "      <td>0.030029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item     score\n",
       "0  1663  0.030029"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for a single user\n",
    "rec_u_i = algo.recommend(train['user'].unique()[2], 1)\n",
    "#rec_u_i = algo.predict_for_user(train['user'].unique()[2], [1,2])\n",
    "rec_u_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map Recommendation Index to Song ID and retrieve meta data from DFLookUp\n",
    "user_i_playlist_recommendations = []\n",
    "for i in rec_u_i['item'].tolist():\n",
    "    user_i_playlist_recommendations.append(DFLookUp.loc[i].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'artist_name': 'Zedd',\n",
       "  'track_uri': 'spotify:track:0dA2Mk56wEzDgegdC6R17g',\n",
       "  'artist_uri': 'spotify:artist:2qxJFvFYMEDqd7ui6kSAcq',\n",
       "  'track_name': 'Stay (with Alessia Cara)',\n",
       "  'album_uri': 'spotify:album:0VMGOBhLrC5Q2bfZnrocVN',\n",
       "  'duration_ms': 210090,\n",
       "  'album_name': 'Stay'}]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_i_playlist_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m recs \u001b[39m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m user \u001b[39min\u001b[39;00m train[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique(): \n\u001b[0;32m----> 4\u001b[0m     user_recs \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39;49mrecommend(user, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m     recs[user] \u001b[39m=\u001b[39m user_recs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lenskit/algorithms/ranking.py:77\u001b[0m, in \u001b[0;36mTopN.recommend\u001b[0;34m(self, user, n, candidates, ratings)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m candidates \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     candidates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselector\u001b[39m.\u001b[39mcandidates(user, ratings)\n\u001b[0;32m---> 77\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49mpredict_for_user(user, candidates, ratings)\n\u001b[1;32m     78\u001b[0m scores \u001b[39m=\u001b[39m scores[scores\u001b[39m.\u001b[39mnotna()]\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/lenskit/algorithms/user_knn.py:223\u001b[0m, in \u001b[0;36mUserUser.predict_for_user\u001b[0;34m(self, user, items, ratings)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(ratings) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_index_)  \u001b[39m# ratings is a dense vector\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# now ratings is normalized to be a mean-centered unit vector\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[39m# this means we can dot product to score neighbors\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m# score the neighbors!\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m nsims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrating_matrix_\u001b[39m.\u001b[39;49mmult_vec(ratings)\n\u001b[1;32m    224\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(nsims) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_index_)\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m user \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_index_:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/csr/csr.py:564\u001b[0m, in \u001b[0;36mCSR.mult_vec\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m K\u001b[39m.\u001b[39mmax_nnz:\n\u001b[1;32m    563\u001b[0m     \u001b[39mwith\u001b[39;00m releasing(K\u001b[39m.\u001b[39mto_handle(\u001b[39mself\u001b[39m), K) \u001b[39mas\u001b[39;00m h:\n\u001b[0;32m--> 564\u001b[0m         \u001b[39mreturn\u001b[39;00m K\u001b[39m.\u001b[39;49mmult_vec(h, v)\n\u001b[1;32m    565\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     shards \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shard_rows(K\u001b[39m.\u001b[39mmax_nnz)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/lib/python3.10/site-packages/numba/core/serialize.py:29\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Keep unpickled object via `numba_unpickle` alive.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m _unpickled_memo \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     30\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m        unpickled object\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     key \u001b[39m=\u001b[39m (address, hashed)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run through all users to get recommendations\n",
    "recs = {}\n",
    "for user in train['user'].unique(): \n",
    "    user_recs = algo.recommend(user, 2)\n",
    "    recs[user] = user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map Recommendation Index to Song ID and retrieve meta data from DFLookUp\n",
    "user_i_playlist_recommendations = []\n",
    "for i in rec_u_i['item'].tolist():\n",
    "    user_i_playlist_recommendations.append(DFLookUp.loc[i].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# evaluate the recommender\n",
    "print(topn.precision(rec_u_i, train[train['user']==0], k=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
